# Ollama

Sample using .NET Aspire and Ollama as a service.

You need Ollama to run this sample. And have the phi3:3.8b model.

Start the application and browse to http://localhost:5485/chat/hello,%20I%20am%20laurent to see the answer from the phi SLM.